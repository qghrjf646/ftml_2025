{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6302e003",
   "metadata": {},
   "source": [
    "# Exercise 2: Bayes Risk with Absolute Loss\n",
    "\n",
    "## Question 0 (M)\n",
    "\n",
    "**Propose a function $f: \\mathbb{R} \\to \\mathbb{R}$ that has a zero derivative at some real value $x_0$, but $f(x_0)$ is not a local extremum of the function.**\n",
    "\n",
    "Let us consider the function:\n",
    "\n",
    "$$\n",
    "f(x) = \\begin{cases}\n",
    "    -x^2 & \\text{if } x < 0 \\\\\n",
    "    x^2 & \\text{if } x \\geq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Let us show that $f'(0) = 0$ but $f(0)$ is not a local extremum.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "The right-hand derivative at $x=0$ is:\n",
    "$$\n",
    "\\lim_{x \\to 0^+} \\frac{f(x) - f(0)}{x - 0} = \\lim_{x \\to 0^+} \\frac{x^2 - 0}{x} = \\lim_{x \\to 0^+} x = 0\n",
    "$$\n",
    "\n",
    "The left-hand derivative at $x=0$ is:\n",
    "$$\n",
    "\\lim_{x \\to 0^-} \\frac{f(x) - f(0)}{x - 0} = \\lim_{x \\to 0^-} \\frac{-(x^2) - 0}{x} = \\lim_{x \\to 0^-} -x = 0\n",
    "$$\n",
    "\n",
    "Therefore, $f'(0) = 0$.\n",
    "\n",
    "However, $f(0) = 0$ is not a local extremum. Indeed, in any neighborhood of $0$, $f(x)$ takes both positive and negative values (for $x > 0$, $f(x) > 0$; for $x < 0$, $f(x) < 0$). Thus, there is no neighborhood of $0$ in which $f(0)$ is either a maximum or a minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cdd6a",
   "metadata": {},
   "source": [
    "## Question 1 (M + C):\n",
    "\n",
    "Recall the definition of the median:\n",
    "\n",
    "> The median $m$ of a real random variable $Y$ is any value such that $P(Y \\leq m) \\geq 0.5$ and $P(Y \\geq m) \\geq 0.5$.\n",
    "> For a continuous distribution, the median $m$ satisfies $F_Y(m) = 0.5$ where $F_Y$ is the cumulative distribution function.\n",
    "\n",
    "Let us show, with a concrete example, that the Bayes estimator for the squared loss (the conditional mean) is not, in general, optimal for the absolute loss.\n",
    "\n",
    "**Example:**\n",
    "Suppose $Y|X=x$ is a discrete random variable such that:\n",
    "- $P(Y=0|X=x) = 0.1$\n",
    "- $P(Y=1|X=x) = 0.9$\n",
    "\n",
    "- The conditional mean is:\n",
    "  $$\n",
    "  f^*_{\\text{squared}}(x) = \\mathbb{E}[Y|X=x] = 0 \\cdot 0.1 + 1 \\cdot 0.9 = 0.9\n",
    "  $$\n",
    "- The conditional median is $1$ (since $P(Y < 1) = 0.1 < 0.5$ and $P(Y \\leq 1) = 1 \\geq 0.5$).\n",
    "\n",
    "Now, compute the absolute risk for both estimators:\n",
    "\n",
    "1. **Risk for $f^*_{\\text{squared}}(x) = 0.9$:**\n",
    "   $$\n",
    "   \\mathbb{E}[|Y - 0.9|] = 0.1 \\cdot |0 - 0.9| + 0.9 \\cdot |1 - 0.9| = 0.1 \\cdot 0.9 + 0.9 \\cdot 0.1 = 0.09 + 0.09 = 0.18\n",
    "   $$\n",
    "\n",
    "2. **Risk for $h(x) = 1$ (the median):**\n",
    "   $$\n",
    "   \\mathbb{E}[|Y - 1|] = 0.1 \\cdot |0 - 1| + 0.9 \\cdot |1 - 1| = 0.1 \\cdot 1 + 0.9 \\cdot 0 = 0.1\n",
    "   $$\n",
    "\n",
    "Thus, the estimator $h(x) = 1$ (the median) has a strictly smaller risk for the absolute loss than the mean $0.9$.\n",
    "\n",
    "**Conclusion:**\n",
    "This example shows that the Bayes estimator for the squared loss is not, in general, the Bayes estimator for the absolute loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66132f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e1e16",
   "metadata": {},
   "source": [
    "## Question 2 (M):\n",
    "\n",
    "Let $Y|X=x$ have a continuous density $p_{Y|X=x}(y)$ and a finite first moment. Show that the Bayes predictor for the absolute loss is the conditional median, i.e.,\n",
    "$$\n",
    "f^*_{\\text{absolute}}(x) = \\arg\\min_{z \\in \\mathbb{R}} \\mathbb{E}[|Y - z| \\mid X = x]\n",
    "$$\n",
    "and that this $z$ is the median of $Y|X=x$.\n",
    "\n",
    "**Proof:**\n",
    "Let $g(z) = \\mathbb{E}[|Y - z| \\mid X = x] = \\int_{-\\infty}^{\\infty} |y - z| p_{Y|X=x}(y) dy$.\n",
    "\n",
    "To find the minimizer, we study the sign of $y-z$:\n",
    "- For $y < z$, $|y-z| = -(y-z) = z-y$ and $\\frac{d}{dz}|y-z| = 1$.\n",
    "- For $y \\geq z$, $|y-z| = y-z$ and $\\frac{d}{dz}|y-z| = -1$.\n",
    "\n",
    "So, the derivative of $g(z)$ is:\n",
    "$$\n",
    "\\frac{d}{dz} g(z) = \\int_{-\\infty}^{z} 1 \\cdot p_{Y|X=x}(y) dy + \\int_{z}^{\\infty} (-1) \\cdot p_{Y|X=x}(y) dy\n",
    "$$\n",
    "\n",
    "Recall that the cumulative distribution function (CDF) of $Y|X=x$ is defined as:\n",
    "$$\n",
    "F_{Y|X=x}(z) = \\int_{-\\infty}^z p_{Y|X=x}(y) dy\n",
    "$$\n",
    "\n",
    "So, the first integral is $F_{Y|X=x}(z)$, and the second integral is $-(1 - F_{Y|X=x}(z))$ (since the total probability is 1):\n",
    "$$\n",
    "\\frac{d}{dz} g(z) = F_{Y|X=x}(z) - (1 - F_{Y|X=x}(z)) = 2F_{Y|X=x}(z) - 1\n",
    "$$\n",
    "\n",
    "Set the derivative to zero to find the minimum:\n",
    "$$\n",
    "2F_{Y|X=x}(z) - 1 = 0 \\implies F_{Y|X=x}(z) = 0.5\n",
    "$$\n",
    "Thus, the minimizer $z$ is the median of $Y|X=x$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
